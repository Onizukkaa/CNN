{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat ou Chien !! une méthode d'apprentissage automatique.\n",
    "\n",
    "Dans une entreprise de marketing, on veut faire une étude sur les clients qui fréquentent un grand magasin. L'idée est d'estimer le pourcentage de clients qui ont des chats et ceux qui ont des chiens, afin de prendre des décisions marketing ciblées. Vous proposez d'utiliser une caméra pour détecter et compter les deux animaux dans le magasin. La première étape du projet est de développer un modèle qui peut détecter le chat ou le chien. Ainsi, dans ce brief, en utilisant une base de données, vous allez entrainer un modèle d'apprentissage automatique avec un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veille technologique: Opencv python\n",
    "\n",
    "- Préparation données imagerie pour méthode classique d'apprentissage automatique\n",
    "- Entrainement et évaluation (similaire aux briefs précédents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use opencv to load and display the image\n",
    "import os\n",
    "from os import listdir\n",
    "import cv2\n",
    "from skimage.io import imread, imsave, imshow\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from numpy import save, asarray\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer data \n",
    "size = 150\n",
    "# repertoir d'images avec deux sous dossiers \"Cat\" et \"Dog\"\n",
    "image_directory = r\"C:/Users/utilisateur/Downloads/kagglecatsanddogs_3367a/PetImages\"\n",
    "images = []  # liste pour images  \n",
    "label = []  # liste pour Label (0 ou 1) pour deux classes.\n",
    "\n",
    "# utiliser \"os\" pour avoir les noms des images dans chaque sous dossier\n",
    "cat_images = os.listdir(\"PetImages/Cat\")\n",
    "dog_images = os.listdir(\"PetImages/Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur sur l'image 10404.jpg\n",
      "erreur sur l'image 2939.jpg\n",
      "erreur sur l'image 5686.jpg\n",
      "erreur sur l'image 666.jpg\n",
      "erreur sur l'image 7276.jpg\n",
      "erreur sur l'image 11702.jpg\n",
      "erreur sur l'image 1308.jpg\n",
      "erreur sur l'image 1773.jpg\n",
      "erreur sur l'image 3823.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:822: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "#boucle\n",
    "\n",
    "dim=(size,size)\n",
    "\n",
    "#chat\n",
    "for file_name in cat_images:\n",
    "    path=image_directory+\"/Cat/\"+file_name\n",
    "    try:\n",
    "        img=imread(path)\n",
    "        img=cv2.resize(img,dim,interpolation=cv2.INTER_AREA)\n",
    "        img=np.array(img)\n",
    "        \n",
    "        \n",
    "        if(img.shape[2]>3):\n",
    "            img_temp=np.copy(img[:,:,0:3])\n",
    "            img=np.copy(img_temp)\n",
    "            \n",
    "    except:\n",
    "            print(f\"erreur sur l'image {file_name}\")\n",
    "    \n",
    "    else:\n",
    "        images.append(img)\n",
    "        label.append(0)\n",
    "        \n",
    "    \n",
    "    \n",
    "#chien\n",
    "for file_name in dog_images:\n",
    "    path=image_directory+\"/Dog/\"+file_name\n",
    "    try:\n",
    "        img=imread(path)\n",
    "        img=cv2.resize(img,dim,interpolation=cv2.INTER_AREA)\n",
    "        img=np.array(img)\n",
    "        \n",
    "        \n",
    "        if(img.shape[2]>3):\n",
    "            img_temp=np.copy(img[:,:,0:3])\n",
    "            img=np.copy(img_temp)\n",
    "            \n",
    "    except:\n",
    "        print(f\"erreur sur l'image {file_name}\")\n",
    "        \n",
    "    else:\n",
    "        images.append(img)\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# utiliser une boucle pour lire chaque image, redimensionner en (150,150,3),\\n# et la mettre dans images, et mettre le label(0 ou 1) selon le type dans \"label\"\\n\\nfor file in listdir(\"PetImages/Dog/\"):\\n   \\n    #load image\\n    \\n    try:\\n        image=np.float32(load_img(\"PetImages/Dog/\"+file))\\n        resized=cv2.resize(image,(size,size), interpolation=cv2.INTER_AREA)\\n      \\n        #convert to numpy array\\n        image=img_to_array(image)\\n        images.append(image)\\n        label.append(0)\\n        \\n    except:\\n        print(f\"erreur sur l\\'image {file}\")\\n        \\n    #else:\\n        #images.append(image)\\n        #label.append(0)\\n\\n\\nfor file in listdir(\"PetImages/Cat/\"):\\n    \\n   \\n    #load image\\n    \\n    try:\\n        image=np.float32(load_img(\"PetImages/Cat/\"+file))\\n        resized=cv2.resize(image,(size,size), interpolation=cv2.INTER_AREA)\\n        #convert to numpy array\\n        image=img_to_array(image)\\n        images.append(image)\\n        label.append(1)\\n    except:\\n        print(f\"erreur sur l\\'image {file}\")\\n        \\n    #else:\\n        #images.append(image)\\n        #label.append(1)\\n\\n\\n    \\n    #convert to a numpy array\\nimages=asarray(images)\\nlabel=asarray(label)\\n            \\n# il y a des images corrumpues, utiliser try ... catch except pour les ignorer\\n\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# utiliser une boucle pour lire chaque image, redimensionner en (150,150,3),\n",
    "# et la mettre dans images, et mettre le label(0 ou 1) selon le type dans \"label\"\n",
    "\n",
    "for file in listdir(\"PetImages/Dog/\"):\n",
    "   \n",
    "    #load image\n",
    "    \n",
    "    try:\n",
    "        image=np.float32(load_img(\"PetImages/Dog/\"+file))\n",
    "        resized=cv2.resize(image,(size,size), interpolation=cv2.INTER_AREA)\n",
    "      \n",
    "        #convert to numpy array\n",
    "        image=img_to_array(image)\n",
    "        images.append(image)\n",
    "        label.append(0)\n",
    "        \n",
    "    except:\n",
    "        print(f\"erreur sur l'image {file}\")\n",
    "        \n",
    "    #else:\n",
    "        #images.append(image)\n",
    "        #label.append(0)\n",
    "\n",
    "\n",
    "for file in listdir(\"PetImages/Cat/\"):\n",
    "    \n",
    "   \n",
    "    #load image\n",
    "    \n",
    "    try:\n",
    "        image=np.float32(load_img(\"PetImages/Cat/\"+file))\n",
    "        resized=cv2.resize(image,(size,size), interpolation=cv2.INTER_AREA)\n",
    "        #convert to numpy array\n",
    "        image=img_to_array(image)\n",
    "        images.append(image)\n",
    "        label.append(1)\n",
    "    except:\n",
    "        print(f\"erreur sur l'image {file}\")\n",
    "        \n",
    "    #else:\n",
    "        #images.append(image)\n",
    "        #label.append(1)\n",
    "\n",
    "\n",
    "    \n",
    "    #convert to a numpy array\n",
    "images=asarray(images)\n",
    "label=asarray(label)\n",
    "            \n",
    "# il y a des images corrumpues, utiliser try ... catch except pour les ignorer\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49982\n",
      "49982\n"
     ]
    }
   ],
   "source": [
    "# show shape\n",
    "print(len(images))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer les listes en numpy \n",
    "np_images = np.array(images)\n",
    "np_label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save data as \".npy\" file\n",
    "np.save(\"dog_cat_images.npy\",images)\n",
    "np.save(\"dog_cat_label.npy\",label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49982, 150, 150, 3)\n",
      "(49982,)\n"
     ]
    }
   ],
   "source": [
    "# show shape\n",
    "print(np_images.shape)\n",
    "print(np_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classical machine learning model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(\"dog_cat_images.npy\")\n",
    "y=np.load(\"dog_cat_label.npy\")\n",
    "X_reshaped=np.reshape(X,(X.shape[0],150*150*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49982, 67500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split les données en train et test avec \"stratification\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.33, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33487, 67500)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 67500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8372"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4124"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, random_state=0, verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialiser le classifierc\n",
    "clf=RandomForestClassifier(n_estimators=100,max_depth=20,random_state=0,verbose=2)\n",
    "#entrainer le classifier\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        chat       0.70      0.78      0.74     12371\n",
      "       chien       0.00      0.00      0.00      4124\n",
      "\n",
      "    accuracy                           0.59     16495\n",
      "   macro avg       0.35      0.39      0.37     16495\n",
      "weighted avg       0.53      0.59      0.55     16495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "# predire\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluer avec classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"chat\",\"chien\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Créer répertoires\n",
    "dataset_home=\"dataset_dogs_vs_cats/\"\n",
    "subdirs=[\"train/\",\"test/\"]\n",
    "for subdir in subdirs:\n",
    "    #create label subdirectories\n",
    "    labeldirs=[\"dogs/\",\"cats/\"]\n",
    "    for labldir in labeldirs:\n",
    "        newdir=dataset_home+subdir+labldir\n",
    "        os.makedirs(newdir,exist_ok=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#retenir au hasard 25% des images dans l'ensemble de données de test\n",
    "#seed random number generator\n",
    "seed(1)\n",
    "#define ration of picture to use for validation\n",
    "val_ratio=0.25\n",
    "#copy training dataset images into subdirectories\n",
    "src_directory=\"C:/Users/utilisateur/dataset_dogs_vs_cats/train\"\n",
    "for file in listdir(src_directory):\n",
    "    src=src_directory+\"/\"+file\n",
    "    dst_dir=\"train/\"\n",
    "    if random()<val_ratio:\n",
    "        dst_dir=\"test/\"\n",
    "    if file.startswith(\"1\"):\n",
    "        dst=dataset_home+dst_dir+\"cats/\"+file\n",
    "        copyfile(src,dst)\n",
    "    elif file.startswith(\"0\"):\n",
    "        dst=dataset_home+dst_dir+\"dogs/\"+file\n",
    "        copyfile(src,dst)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayer de normaliser chaque image entre 0 et 255 et rentrainer le modèle. Y a-t-il une amélioration ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networ MLP\n",
    "\n",
    "Entrainer un modèle MLP pour detecter la class Dog ou Cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PCA to reduce dimensions\n",
    "# check this tuto: https://www.askpython.com/python/examples/principal-component-analysis-for-image-data\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# creer un reseau de neurone avec une couche d'entrée de taille (150*150*3), deux couches caché de taille 128 et une activation \"relu\". \n",
    "# Dernière couche de taille 1 avec une activation sigmoid. Choisir la bonne \"loss function\" et \"optimizer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainer le modèle avec validation_split = 2, epochs = 20, et un batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "def create_model(lyrs=128,activation=\"relu\", optimizer=\"adam\", loss='SparseCategoricalCrossentropy', dr=0.2):\n",
    "    num_classes = 2\n",
    "    \n",
    "    #Set ranfom seed for reproducibility\n",
    "    seed(42)\n",
    "    set_seed(42)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.experimental.preprocessing.Rescaling(1./255)),#normalise de 0 a 1\n",
    "    #model.add(layers.Conv2D(lyrs,(4,4), activation='relu'))\n",
    "    #model.add(layers.MaxPooling2D())#réduit l'image\n",
    "    #model.add(layers.Conv2D(64,(4,4), activation='relu'))\n",
    "    #model.add(layers.MaxPooling2D())#prend le max du pooling\n",
    "    #model.add(layers.Conv2D(32,(4,4), activation='relu'))\n",
    "    #model.add(layers.MaxPooling2D())\n",
    "    #model.add(layers.Conv2D(16,(4,4), activation='relu'))\n",
    "    #model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Flatten())#permet de construire un vecteur\n",
    "    model.add(layers.Dense(lyrs,activation=activation))\n",
    "    model.add(layers.Dense(64,activation=activation))\n",
    "    model.add(layers.Dense(32,activation=activation))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "      metrics=['accuracy'],)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix pour chaque paramètre\n",
    "activation = [\"relu\", \"sigmoid\"]\n",
    "optimizer = [\"adam\", \"adagrad\",\"RMSprop\",\"SGD\",\"Adadelta\",\"Ftrl\",\"softmax\"]\n",
    "unit = [[1,8],[8],[10],[10,5],[12,6],[12,8,4]]\n",
    "loss=[\"sparse_categorical_crossentropy\",\"mean_squared_error\",]\n",
    "drops = [0.0,1.0]\n",
    "nb_epoch = [10, 600]\n",
    "batch_size = [1,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 224 candidates, totalling 2240 fits\n",
      "[CV] END activation=relu, batch_size=1, dr=0.0, loss=sparse_categorical_crossentropy, nb_epoch=10, optimizer=adam; total time=17.7min\n",
      "[CV] END activation=relu, batch_size=1, dr=0.0, loss=sparse_categorical_crossentropy, nb_epoch=10, optimizer=adam; total time=17.1min\n",
      "[CV] END activation=relu, batch_size=1, dr=0.0, loss=sparse_categorical_crossentropy, nb_epoch=10, optimizer=adam; total time=17.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(activation\u001b[38;5;241m=\u001b[39mactivation, \n\u001b[0;32m      2\u001b[0m                   optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m      3\u001b[0m                   loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m      4\u001b[0m                   dr\u001b[38;5;241m=\u001b[39mdrops,\n\u001b[0;32m      5\u001b[0m                   nb_epoch\u001b[38;5;241m=\u001b[39mnb_epoch, \n\u001b[0;32m      6\u001b[0m                   batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      8\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparams,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;66;03m# include n_jobs=-1 if you are using CPU\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m grid_result\u001b[38;5;241m=\u001b[39m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:223\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid shape for y: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKerasClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:166\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m fit_args \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_sk_params(Sequential\u001b[38;5;241m.\u001b[39mfit))\n\u001b[0;32m    164\u001b[0m fit_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m--> 166\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = dict(activation=activation, \n",
    "                  optimizer=optimizer, \n",
    "                  loss=loss,\n",
    "                  dr=drops,\n",
    "                  nb_epoch=nb_epoch, \n",
    "                  batch_size=batch_size)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=params,cv=10,verbose=2)# include n_jobs=-1 if you are using CPU\n",
    "grid_result=grid.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result.best_params_)\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_model(lyrs=128,activation=\"relu\", optimizer=\"adam\", loss='SparseCategoricalCrossentropy', dr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "210/210 [==============================] - 17s 83ms/step - loss: 1.3642 - accuracy: 0.6501 - val_loss: 0.9613 - val_accuracy: 0.3174\n",
      "Epoch 2/20\n",
      "210/210 [==============================] - 17s 82ms/step - loss: 0.6607 - accuracy: 0.6977 - val_loss: 0.7662 - val_accuracy: 0.4606\n",
      "Epoch 3/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.6293 - accuracy: 0.7104 - val_loss: 0.6559 - val_accuracy: 0.7462\n",
      "Epoch 4/20\n",
      "210/210 [==============================] - 17s 80ms/step - loss: 0.5818 - accuracy: 0.7325 - val_loss: 0.5804 - val_accuracy: 0.7462\n",
      "Epoch 5/20\n",
      "210/210 [==============================] - 17s 80ms/step - loss: 0.5711 - accuracy: 0.7419 - val_loss: 0.5925 - val_accuracy: 0.7460\n",
      "Epoch 6/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.5662 - accuracy: 0.7407 - val_loss: 0.6508 - val_accuracy: 0.5796\n",
      "Epoch 7/20\n",
      "210/210 [==============================] - 17s 82ms/step - loss: 0.5654 - accuracy: 0.7443 - val_loss: 0.5739 - val_accuracy: 0.7405\n",
      "Epoch 8/20\n",
      "210/210 [==============================] - 17s 83ms/step - loss: 0.5482 - accuracy: 0.7497 - val_loss: 0.5881 - val_accuracy: 0.7444\n",
      "Epoch 9/20\n",
      "210/210 [==============================] - 17s 83ms/step - loss: 0.5555 - accuracy: 0.7495 - val_loss: 0.5589 - val_accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "210/210 [==============================] - 18s 88ms/step - loss: 0.5586 - accuracy: 0.7465 - val_loss: 0.5687 - val_accuracy: 0.7462\n",
      "Epoch 11/20\n",
      "210/210 [==============================] - 18s 88ms/step - loss: 0.5574 - accuracy: 0.7497 - val_loss: 0.5570 - val_accuracy: 0.7459\n",
      "Epoch 12/20\n",
      "210/210 [==============================] - 18s 88ms/step - loss: 0.5469 - accuracy: 0.7509 - val_loss: 0.5568 - val_accuracy: 0.7462\n",
      "Epoch 13/20\n",
      "210/210 [==============================] - 17s 80ms/step - loss: 0.5488 - accuracy: 0.7505 - val_loss: 0.5614 - val_accuracy: 0.7428\n",
      "Epoch 14/20\n",
      "210/210 [==============================] - 17s 80ms/step - loss: 0.5480 - accuracy: 0.7478 - val_loss: 0.5665 - val_accuracy: 0.7462\n",
      "Epoch 15/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.5473 - accuracy: 0.7502 - val_loss: 0.5549 - val_accuracy: 0.7459\n",
      "Epoch 16/20\n",
      "210/210 [==============================] - 18s 83ms/step - loss: 0.5500 - accuracy: 0.7495 - val_loss: 0.5614 - val_accuracy: 0.7462\n",
      "Epoch 17/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.5447 - accuracy: 0.7505 - val_loss: 0.5655 - val_accuracy: 0.7462\n",
      "Epoch 18/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.5531 - accuracy: 0.7502 - val_loss: 0.5702 - val_accuracy: 0.7462\n",
      "Epoch 19/20\n",
      "210/210 [==============================] - 17s 81ms/step - loss: 0.5531 - accuracy: 0.7504 - val_loss: 0.5617 - val_accuracy: 0.7462\n",
      "Epoch 20/20\n",
      "210/210 [==============================] - 17s 82ms/step - loss: 0.5500 - accuracy: 0.7508 - val_loss: 0.5549 - val_accuracy: 0.7462\n"
     ]
    }
   ],
   "source": [
    "history=model.fit( X_train,y_train,epochs=20,\n",
    "                  batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_86 (Rescaling)     (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 67500)             0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 128)               8640128   \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 8,650,530\n",
      "Trainable params: 8,650,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81239176 0.18760817]\n",
      " [0.7006967  0.29930326]\n",
      " [0.6289593  0.37104073]\n",
      " ...\n",
      " [0.7998688  0.20013125]\n",
      " [0.67256624 0.32743374]\n",
      " [0.6957559  0.30424407]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate MLP\n",
    "# evaluate classifier\n",
    "from sklearn.metrics import classification_report\n",
    "# predire\n",
    "y_pred=model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16495, 2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047/1047 [==============================] - 17s 17ms/step - loss: 0.5461 - accuracy: 0.7500\n",
      "516/516 [==============================] - 9s 18ms/step - loss: 0.5524 - accuracy: 0.7500\n",
      "Train ; 0.7499925494194031, Test: 0.749984860420227\n"
     ]
    }
   ],
   "source": [
    "_,train_acc=model.evaluate(X_train,y_train)\n",
    "_,test_acc=model.evaluate(X_test,y_test)\n",
    "print(f\"Train ; {train_acc}, Test: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Courbe d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e29c752e75e91034d0c40602915a17cb0379d8f99d244b8deba46517b7d2192"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
